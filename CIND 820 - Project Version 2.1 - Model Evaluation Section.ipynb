{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34234267",
   "metadata": {},
   "source": [
    "# CIND 820 - Deliverable 3 - Model Evaluation\n",
    "## Data Analysis Section\n",
    "\n",
    "This section of the notebook aims to train and test 3 different supervised machine learning models on its performance with regard to predicting star-ratings based on user feedback. The notebook will be broken down into 3-main sections:\n",
    "\n",
    "1. Data preparation\n",
    "\n",
    "2. Model Training and Implementation\n",
    "\n",
    "    1. Model Training for Logistic Regression Algorithm\n",
    "\n",
    "    2. Model Training for a Naive Bayes Algorithm\n",
    "\n",
    "    3. Model Training for a Support Vector Regression Algorithm\n",
    "    \n",
    "3. Model Performance Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e880c44c",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576c519c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>num_Tokens</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>aaron</th>\n",
       "      <th>...</th>\n",
       "      <th>yr</th>\n",
       "      <th>yuck</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>étouffée</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CoCim4CRm-WCoU-CFfWpLw</td>\n",
       "      <td>McdCFYocB1hFIiDQBRQ7YA</td>\n",
       "      <td>P_nqb7lULOtx3pAJbKfFXA</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.0209</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8s6Eejmy24XUhgNkR2uIUA</td>\n",
       "      <td>X67DbQdqHeZ-F2UVUOhn1g</td>\n",
       "      <td>WNjrsnJVPPnv_FtHHdjklA</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.6697</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2GdPCXF_5fR4_od5DJTD8Q</td>\n",
       "      <td>-VPeYf78MNJAB0iR7d9-zg</td>\n",
       "      <td>QboMIy08NLnBbLXEsmnDHg</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.9612</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vYSCzz-jM7ibdoIUCRLysw</td>\n",
       "      <td>I0Vt1g8iK0D_cxXkJyXb0A</td>\n",
       "      <td>INz7vujcHs0AggsV__pXYQ</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6449</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mLokfOcquwIP57pcOkHBZQ</td>\n",
       "      <td>TV3p-bv5yh8RgdJ3WxM7Ug</td>\n",
       "      <td>eh8WfQqPa2ZWtbXe9_wHgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.3201</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  CoCim4CRm-WCoU-CFfWpLw  McdCFYocB1hFIiDQBRQ7YA  P_nqb7lULOtx3pAJbKfFXA   \n",
       "1  8s6Eejmy24XUhgNkR2uIUA  X67DbQdqHeZ-F2UVUOhn1g  WNjrsnJVPPnv_FtHHdjklA   \n",
       "2  2GdPCXF_5fR4_od5DJTD8Q  -VPeYf78MNJAB0iR7d9-zg  QboMIy08NLnBbLXEsmnDHg   \n",
       "3  vYSCzz-jM7ibdoIUCRLysw  I0Vt1g8iK0D_cxXkJyXb0A  INz7vujcHs0AggsV__pXYQ   \n",
       "4  mLokfOcquwIP57pcOkHBZQ  TV3p-bv5yh8RgdJ3WxM7Ug  eh8WfQqPa2ZWtbXe9_wHgQ   \n",
       "\n",
       "   stars  num_Tokens    neg    neu    pos  compound  aaron  ...  yr  yuck  \\\n",
       "0      1          48  0.119  0.779  0.102   -0.0209      0  ...   0     0   \n",
       "1      1          84  0.110  0.819  0.071   -0.6697      0  ...   0     0   \n",
       "2      1          27  0.276  0.690  0.034   -0.9612      0  ...   0     0   \n",
       "3      1           6  0.222  0.778  0.000   -0.6449      0  ...   0     0   \n",
       "4      1          44  0.055  0.919  0.026   -0.3201      0  ...   0     0   \n",
       "\n",
       "   yum  yummy  yup  zero  zone  zoo  zucchini  étouffée  \n",
       "0    0      0    0     0     0    0         0         0  \n",
       "1    0      0    0     0     0    0         0         0  \n",
       "2    0      0    0     0     0    0         0         0  \n",
       "3    0      0    0     0     0    0         0         0  \n",
       "4    0      0    0     0     0    0         0         0  \n",
       "\n",
       "[5 rows x 5008 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing pandas library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#MacOS Version of Filepath\n",
    "filepathMac = r\"/Users/sszhang/Documents/Learning Data Analytics/TMU Certificate copy/CIND 820/Yelp Dataset/balancedDataBoW.csv\"\n",
    "# filepathWindows = r\"C:\\Users\\Sunora\\iCloudDrive\\Documents\\Learning Data Analytics\\TMU Certificate copy\\CIND 820\\Yelp Dataset\\balancedDataBoW.csv\"\n",
    "data = pd.read_csv(filepathMac)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8146557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>num_Tokens</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>ability</th>\n",
       "      <th>...</th>\n",
       "      <th>yr</th>\n",
       "      <th>yuck</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>étouffée</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.0209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.6697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.9612</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6449</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.3201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars  num_Tokens    neg    neu    pos  compound  aaron  aback  abandon  \\\n",
       "0      1          48  0.119  0.779  0.102   -0.0209      0      0        0   \n",
       "1      1          84  0.110  0.819  0.071   -0.6697      0      0        0   \n",
       "2      1          27  0.276  0.690  0.034   -0.9612      0      0        0   \n",
       "3      1           6  0.222  0.778  0.000   -0.6449      0      0        0   \n",
       "4      1          44  0.055  0.919  0.026   -0.3201      0      0        0   \n",
       "\n",
       "   ability  ...  yr  yuck  yum  yummy  yup  zero  zone  zoo  zucchini  \\\n",
       "0        0  ...   0     0    0      0    0     0     0    0         0   \n",
       "1        0  ...   0     0    0      0    0     0     0    0         0   \n",
       "2        0  ...   0     0    0      0    0     0     0    0         0   \n",
       "3        0  ...   0     0    0      0    0     0     0    0         0   \n",
       "4        0  ...   0     0    0      0    0     0     0    0         0   \n",
       "\n",
       "   étouffée  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 5005 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping 'review_id', 'user_id', and 'business_id' fields\n",
    "data.drop(columns=['review_id', 'user_id', 'business_id'], inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82836615",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "All three ML models will use the following features: 1) Star Rating, 2) the 4 different sentiment scores generated by VADER, and 3) the Bag of Words matrix.\n",
    "\n",
    "### Training and Testing Setup\n",
    "For the sake of consistency we will be training and testing all 3 models using the same methods:\n",
    "\n",
    "- Utilize an 80% training size (equivalent to 20,000 rows of data)\n",
    "\n",
    "- Utilize a 20% test size (equivalent to 5,000 rows of data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e77dfd",
   "metadata": {},
   "source": [
    "## Model Training and Implementation\n",
    "### Preloading all dependent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b141d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931acbc",
   "metadata": {},
   "source": [
    "### 1. Model Training for Logistic Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be58de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sunora\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5154\n",
      "Confusion Matrix:\n",
      " [[659 233  63  24  23]\n",
      " [234 439 224  53  26]\n",
      " [ 69 238 396 238  80]\n",
      " [ 23  53 182 428 313]\n",
      " [ 15  30  62 240 655]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.66      0.66      1002\n",
      "           2       0.44      0.45      0.45       976\n",
      "           3       0.43      0.39      0.41      1021\n",
      "           4       0.44      0.43      0.43       999\n",
      "           5       0.60      0.65      0.62      1002\n",
      "\n",
      "    accuracy                           0.52      5000\n",
      "   macro avg       0.51      0.52      0.51      5000\n",
      "weighted avg       0.51      0.52      0.51      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Defining the Target Variable (Y = 'stars' column) and Feature Set (X = all other columns)\n",
    "Y = data['stars']\n",
    "X = data.drop(columns = 'stars')\n",
    "\n",
    "# Splitting the data into training and testing components\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2025)\n",
    "\n",
    "# Specifying a Logistic Regression algorithm\n",
    "model = LogisticRegression(max_iter=5000, solver='lbfgs', multi_class='multinomial')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf23b6f2",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "Based on the Confusion Matrix output for our **Logistic Regression model**, we quickly observe the following:\n",
    "\n",
    "- **Precision**, a metric that measures how accurate a model is at categorizing star-ratings, was highest for 1-star and 5-star reviews but suffered between 2-4 star ratings. For instance, the model scored a 66% on precision for 1-star ratings which means that 66% of the model's predictions for 1-star ratings were truly 1-stars. In other words, it can be thought of as the probability of a model's prediction being correct. \n",
    "\n",
    "- **Recall**, a metric that measures how complete a model is at capturing the right star-ratings, was also highest for 1-star and 5-star reviews and also suffered between 2-4 star ratings. For instance, the model scored a 66% on recall for 1-star ratings which means that 66% of all 1-star ratings were identified.  \n",
    "\n",
    "- **F1-Score**, a harmonized metric that takes the average of the **precision** and **recall** score, is therefore also aligned in that both 1-star and 5-star categories had the highest score. \n",
    "\n",
    "- **Accuracy**, a metric that measures the overall correctness of a model across all categories, was 52%, indicating that the model correctly predicted just over half of all reviews. While this is better than random guessing (which would yield ~20% in a 5-class setup), it still reflects substantial room for improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f987c56",
   "metadata": {},
   "source": [
    "### 2. Model Training for Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf5317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5226\n",
      "Confusion Matrix:\n",
      " [[670 239  73   6  14]\n",
      " [215 387 287  61  26]\n",
      " [ 86 164 427 280  64]\n",
      " [ 45  28 156 515 255]\n",
      " [ 53  14  43 278 614]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.67      0.65      1002\n",
      "           2       0.47      0.40      0.43       976\n",
      "           3       0.43      0.42      0.43      1021\n",
      "           4       0.45      0.52      0.48       999\n",
      "           5       0.63      0.61      0.62      1002\n",
      "\n",
      "    accuracy                           0.52      5000\n",
      "   macro avg       0.52      0.52      0.52      5000\n",
      "weighted avg       0.52      0.52      0.52      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing MultinomialNB from sklearn.naive_bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Revoving negatives from compound score to use Naive Bayes\n",
    "data_nb = data.copy()\n",
    "data_nb['compound'] = data_nb['compound'] + 1  # Shift to non-negative\n",
    "\n",
    "# Defining the Target Variable (Y = 'stars' column) and Feature Set (X = all other columns)\n",
    "Y = data_nb['stars']\n",
    "X = data_nb.drop(columns = 'stars')\n",
    "\n",
    "# Splitting the data into training and testing components\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2025)\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions with the Naive Bayes model\n",
    "nb_y_pred = nb_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, nb_y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, nb_y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(Y_test, nb_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b5f82",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "Based on the Confusion Matrix output for our **Naive Bayes model**, we quickly observe the following:\n",
    "\n",
    "- **Precision**, a metric that measures how accurate a model is at categorizing star-ratings, was highest for 1-star and 5-star reviews but suffered between 2-4 star ratings. For instance, the model scored a 63% on precision for 1-star ratings which means that 63% of the model's predictions for 1-star ratings were truly 1-stars. In other words, it can be thought of as the probability of a model's prediction being correct. \n",
    "\n",
    "- **Recall**, a metric that measures how complete a model is at capturing the right star-ratings, was also highest for 1-star and 5-star reviews and also suffered between 2-4 star ratings. For instance, the model scored a 67% on recall for 1-star ratings which means that 67% of all 1-star ratings were identified.  \n",
    "\n",
    "- **F1-Score**, a harmonized metric that takes the average of the **precision** and **recall** score, is therefore also aligned in that both 1-star and 5-star categories had the highest score. \n",
    "\n",
    "- **Accuracy**, a metric that measures the overall correctness of a model across all categories, was 52%, indicating that the model correctly predicted just over half of all reviews. While this is better than random guessing (which would yield ~20% in a 5-class setup), it still reflects substantial room for improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c81c5",
   "metadata": {},
   "source": [
    "### 3. Model Training for Regression-Support Vector Machine Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471274c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.364657920850164\n",
      "R^2 Score: 0.3170491581973893\n",
      "Rounded Accuracy: 0.4018\n",
      "Confusion Matrix:\n",
      " [[399 387 178  29   9]\n",
      " [212 368 301  77  18]\n",
      " [ 61 212 426 259  63]\n",
      " [ 15  53 260 449 222]\n",
      " [  7  22 162 444 367]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.40      0.47      1002\n",
      "           2       0.35      0.38      0.36       976\n",
      "           3       0.32      0.42      0.36      1021\n",
      "           4       0.36      0.45      0.40       999\n",
      "           5       0.54      0.37      0.44      1002\n",
      "\n",
      "    accuracy                           0.40      5000\n",
      "   macro avg       0.43      0.40      0.41      5000\n",
      "weighted avg       0.43      0.40      0.41      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Defining the Target Variable (Y = 'stars' column) and Feature Set (X = all other columns)\n",
    "Y = data['stars']\n",
    "X = data.drop(columns = 'stars')\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting the data into training and testing components\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=2025)\n",
    "\n",
    "# Specifying a Support Vector Regression algorithm\n",
    "svr_model = LinearSVR(max_iter = 10000)\n",
    "svr_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions with the SVR model\n",
    "svr_y_pred = svr_model.predict(X_test)\n",
    "\n",
    "# Evaluating the SVR model\n",
    "print(\"Mean Squared Error:\", mean_squared_error(Y_test, svr_y_pred))\n",
    "print(\"R^2 Score:\", r2_score(Y_test, svr_y_pred))\n",
    "\n",
    "# Rounding predictions to nearest integer for classification evaluation\n",
    "svr_y_pred_rounded = np.clip(np.round(svr_y_pred), 1, 5).astype(int)\n",
    "print(\"Rounded Accuracy:\", accuracy_score(Y_test, svr_y_pred_rounded))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, svr_y_pred_rounded))\n",
    "print(\"Classification Report:\\n\", classification_report(Y_test, svr_y_pred_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e891da3c",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "Based on the Confusion Matrix output for our **Support Vector Regression model**, we quickly observe the following:\n",
    "\n",
    "- **Precision**, a metric that measures how accurate a model is at categorizing star-ratings, was highest for 1-star and 5-star reviews but suffered between 2-4 star ratings. For instance, the model scored a 57% on precision for 1-star ratings which means that 57% of the model's predictions for 1-star ratings were truly 1-stars. In other words, it can be thought of as the probability of a model's prediction being correct. \n",
    "\n",
    "- **Recall**, a metric that measures how complete a model is at capturing the right star-ratings, was highest for 4-star reviews. For instance, the model scored a 45% on recall for 4-star ratings which means that 45% of all 4-star ratings were identified.  \n",
    "\n",
    "- **F1-Score**, a harmonized metric that takes the average of the **precision** and **recall** score, showed that both 1-star and 5-star categories had the highest harmonized score. \n",
    "\n",
    "- **Accuracy**, a metric that measures the overall correctness of a model across all categories, was 40%. This suggests that the SVR model underperformed both the Logistic Regression and Naive Bayes models.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
